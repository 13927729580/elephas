<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Documentation for Elephas, Distributed Deep Learning with Keras & Spark">
  
  <link rel="shortcut icon" href="img/favicon.ico">
  <title>Home - Elephas Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="css/theme.css" type="text/css" />
  <link rel="stylesheet" href="css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Home";
    var mkdocs_page_input_path = "index.md";
    var mkdocs_page_url = "/elephas/";
  </script>
  
  <script src="js/jquery-2.1.1.min.js" defer></script>
  <script src="js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> Elephas Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1 current">
		
    <a class="current" href=".">Home</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#elephas-distributed-deep-learning-with-keras-spark">Elephas: Distributed Deep Learning with Keras &amp; Spark</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#introduction">Introduction</a></li>
        
            <li><a class="toctree-l3" href="#getting-started">Getting started</a></li>
        
            <li><a class="toctree-l3" href="#basic-spark-integration">Basic Spark integration</a></li>
        
            <li><a class="toctree-l3" href="#spark-mllib-integration">Spark MLlib integration</a></li>
        
            <li><a class="toctree-l3" href="#spark-ml-integration">Spark ML integration</a></li>
        
            <li><a class="toctree-l3" href="#distributed-hyper-parameter-optimization">Distributed hyper-parameter optimization</a></li>
        
            <li><a class="toctree-l3" href="#distributed-training-of-ensemble-models">Distributed training of ensemble models</a></li>
        
            <li><a class="toctree-l3" href="#discussion">Discussion</a></li>
        
            <li><a class="toctree-l3" href="#literature">Literature</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="why-use-elephas/">Why use Elephas</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Getting started</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="getting-started/getting-started/">Getting started with Elephas</a>
                </li>
                <li class="">
                    
    <a class="" href="getting-started/faq/">FAQ</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Models</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="models/about-elephas-models/">About Elephas models</a>
                </li>
                <li class="">
                    
    <a class="" href="models/spark-model/">SparkModel</a>
                </li>
                <li class="">
                    
    <a class="" href="models/spark-mllib-model/">SparkMLlibModel</a>
                </li>
                <li class="">
                    
    <a class="" href="models/spark-ml-model/">ElephasEstimator</a>
                </li>
                <li class="">
                    
    <a class="" href="models/hyper-param-model/">HyperParamModel</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Parameter server</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="parameter/server/">Servers</a>
                </li>
                <li class="">
                    
    <a class="" href="parameter/client/">Clients</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Utilities</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="utils/rdd_utils/">RDD utils</a>
                </li>
                <li class="">
                    
    <a class="" href="utils/functional_utils/">Functional utils</a>
                </li>
                <li class="">
                    
    <a class="" href="utils/serialization.md">Serialization utils</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Spark ML and MLlib adapters</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="adapters/spark-ml/">Spark ML</a>
                </li>
                <li class="">
                    
    <a class="" href="Spark MLlib; adapters/spark-mllib.md">None</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">Elephas Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>Home</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/maxpumperla/elephas/edit/master/docs/index.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="elephas-distributed-deep-learning-with-keras-spark">Elephas: Distributed Deep Learning with Keras &amp; Spark</h1>
<h2 id="_1"></h2>
<p><a href="https://travis-ci.org/maxpumperla/elephas"><img alt="Build Status" src="https://travis-ci.org/maxpumperla/elephas.svg?branch=master" /></a>
<a href="https://github.com/maxpumperla/elephas/blob/master/LICENSE"><img alt="license" src="https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000" /></a></p>
<p>Elephas is an extension of <a href="http://keras.io">Keras</a>, which allows you to run distributed deep learning models at 
scale with <a href="http://spark.apache.org">Spark</a>. Elephas currently supports a number of 
applications, including:</p>
<ul>
<li><a href="#basic-spark-integration">Data-parallel training of deep learning models</a></li>
<li><a href="#distributed-hyper-parameter-optimization">Distributed hyper-parameter optimization</a></li>
<li><a href="#distributed-training-of-ensemble-models">Distributed training of ensemble models</a></li>
</ul>
<p>Schematically, elephas works as follows.</p>
<p><img alt="Elephas" src="elephas.gif" /></p>
<p>Table of content:
* <a href="#elephas-distributed-deep-learning-with-keras-&amp;-spark-">Elephas: Distributed Deep Learning with Keras &amp; Spark</a>
  * <a href="#introduction">Introduction</a>
  * <a href="#getting-started">Getting started</a>
  * <a href="#basic-spark-integration">Basic Spark integration</a>
  * <a href="#spark-mllib-integration">Spark MLlib integration</a>
  * <a href="#spark-ml-integration">Spark ML integration</a>
  * <a href="#distributed-hyper-parameter-optimization">Distributed hyper-parameter optimization</a>
  * <a href="#distributed-training-of-ensemble-models">Distributed training of ensemble models</a>
  * <a href="#discussion">Discussion</a>
  * <a href="#literature">Literature</a></p>
<h2 id="introduction">Introduction</h2>
<p>Elephas brings deep learning with <a href="http://keras.io">Keras</a> to <a href="http://spark.apache.org">Spark</a>. Elephas intends to 
keep the simplicity and high usability of Keras, thereby allowing for fast prototyping of distributed models, which 
can be run on massive data sets. For an introductory example, see the following 
<a href="https://github.com/maxpumperla/elephas/blob/master/examples/Spark_ML_Pipeline.ipynb">iPython notebook</a>.</p>
<p>ἐλέφας is Greek for <em>ivory</em> and an accompanying project to κέρας, meaning <em>horn</em>. If this seems weird mentioning, like 
a bad dream, you should confirm it actually is at the 
<a href="https://github.com/fchollet/keras/blob/master/README.md">Keras documentation</a>. 
Elephas also means <em>elephant</em>, as in stuffed yellow elephant.</p>
<p>Elephas implements a class of data-parallel algorithms on top of Keras, using Spark's RDDs and data frames. 
Keras Models are initialized on the driver, then serialized and shipped to workers, alongside with data and broadcasted 
model parameters. Spark workers deserialize the model, train their chunk of data and send their gradients back to the 
driver. The "master" model on the driver is updated by an optimizer, which takes gradients either synchronously or
asynchronously.</p>
<h2 id="getting-started">Getting started</h2>
<p>Just install elephas from PyPI with, Spark will be installed through <code>pyspark</code> for you.</p>
<pre><code>pip install elephas
</code></pre>

<p>That's it, you should now be able to run Elephas examples.</p>
<h2 id="basic-spark-integration">Basic Spark integration</h2>
<p>After installing both Elephas, you can train a model as follows. First, create a local pyspark context</p>
<pre><code class="python">from pyspark import SparkContext, SparkConf
conf = SparkConf().setAppName('Elephas_App').setMaster('local[8]')
sc = SparkContext(conf=conf)
</code></pre>

<p>Next, you define and compile a Keras model</p>
<pre><code class="python">from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import SGD
model = Sequential()
model.add(Dense(128, input_dim=784))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(10))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer=SGD())
</code></pre>

<p>and create an RDD from numpy arrays (or however you want to create an RDD)</p>
<pre><code class="python">from elephas.utils.rdd_utils import to_simple_rdd
rdd = to_simple_rdd(sc, x_train, y_train)
</code></pre>

<p>The basic model in Elephas is the <code>SparkModel</code>. You initialize a <code>SparkModel</code> by passing in a compiled Keras model, 
an update frequency and a parallelization mode. After that you can simply <code>fit</code> the model on your RDD. Elephas <code>fit</code>
has the same options as a Keras model, so you can pass <code>epochs</code>, <code>batch_size</code> etc. as you're used to from Keras.</p>
<pre><code class="python">from elephas.spark_model import SparkModel

spark_model = SparkModel(model, frequency='epoch', mode='asynchronous')
spark_model.fit(rdd, epochs=20, batch_size=32, verbose=0, validation_split=0.1)
</code></pre>

<p>Your script can now be run using spark-submit</p>
<pre><code class="bash">spark-submit --driver-memory 1G ./your_script.py
</code></pre>

<p>Increasing the driver memory even further may be necessary, as the set of parameters in a network may be very large 
and collecting them on the driver eats up a lot of resources. See the examples folder for a few working examples.</p>
<h2 id="spark-mllib-integration">Spark MLlib integration</h2>
<p>Following up on the last example, to use Spark's MLlib library with Elephas, you create an RDD of LabeledPoints for 
supervised training as follows</p>
<pre><code class="python">from elephas.utils.rdd_utils import to_labeled_point
lp_rdd = to_labeled_point(sc, x_train, y_train, categorical=True)
</code></pre>

<p>Training a given LabeledPoint-RDD is very similar to what we've seen already</p>
<pre><code class="python">from elephas.spark_model import SparkMLlibModel
spark_model = SparkMLlibModel(model, frequency='batch', mode='hogwild')
spark_model.train(lp_rdd, epochs=20, batch_size=32, verbose=0, validation_split=0.1, 
                  categorical=True, nb_classes=nb_classes)
</code></pre>

<h2 id="spark-ml-integration">Spark ML integration</h2>
<p>To train a model with a SparkML estimator on a data frame, use the following syntax.</p>
<pre><code class="python">df = to_data_frame(sc, x_train, y_train, categorical=True)
test_df = to_data_frame(sc, x_test, y_test, categorical=True)

estimator = ElephasEstimator(model, epochs=epochs, batch_size=batch_size, frequency='batch', mode='asynchronous',
                             categorical=True, nb_classes=nb_classes)
fitted_model = estimator.fit(df)
</code></pre>

<p>Fitting an estimator results in a SparkML transformer, which we can use for predictions and other evaluations by 
calling the transform method on it.</p>
<pre><code class="python">prediction = fitted_model.transform(test_df)
pnl = prediction.select(&quot;label&quot;, &quot;prediction&quot;)
pnl.show(100)

prediction_and_label= pnl.rdd.map(lambda row: (row.label, row.prediction))
metrics = MulticlassMetrics(prediction_and_label)
print(metrics.precision())
print(metrics.recall())
</code></pre>

<h2 id="distributed-hyper-parameter-optimization">Distributed hyper-parameter optimization</h2>
<p>Hyper-parameter optimization with elephas is based on <a href="https://github.com/maxpumperla/hyperas">hyperas</a>, a convenience 
wrapper for hyperopt and keras. Each Spark worker executes a number of trials, the results get collected and the best 
model is returned. As the distributed mode in hyperopt (using MongoDB), is somewhat difficult to configure and error 
prone at the time of writing, we chose to implement parallelization ourselves. Right now, the only available 
optimization algorithm is random search.</p>
<p>The first part of this example is more or less directly taken from the hyperas documentation. We define data and model 
as functions, hyper-parameter ranges are defined through braces. See the hyperas documentation for more on how 
this works.</p>
<pre><code class="python">from __future__ import print_function
from hyperopt import STATUS_OK
from hyperas.distributions import choice, uniform

def data():
    from keras.datasets import mnist
    from keras.utils import np_utils
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(60000, 784)
    x_test = x_test.reshape(10000, 784)
    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')
    x_train /= 255
    x_test /= 255
    nb_classes = 10
    y_train = np_utils.to_categorical(y_train, nb_classes)
    y_test = np_utils.to_categorical(y_test, nb_classes)
    return x_train, y_train, x_test, y_test


def model(x_train, y_train, x_test, y_test):
    from keras.models import Sequential
    from keras.layers.core import Dense, Dropout, Activation
    from keras.optimizers import RMSprop

    model = Sequential()
    model.add(Dense(512, input_shape=(784,)))
    model.add(Activation('relu'))
    model.add(Dropout({{uniform(0, 1)}}))
    model.add(Dense({{choice([256, 512, 1024])}}))
    model.add(Activation('relu'))
    model.add(Dropout({{uniform(0, 1)}}))
    model.add(Dense(10))
    model.add(Activation('softmax'))

    rms = RMSprop()
    model.compile(loss='categorical_crossentropy', optimizer=rms)

    model.fit(x_train, y_train,
              batch_size={{choice([64, 128])}},
              nb_epoch=1,
              show_accuracy=True,
              verbose=2,
              validation_data=(x_test, y_test))
    score, acc = model.evaluate(x_test, y_test, show_accuracy=True, verbose=0)
    print('Test accuracy:', acc)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model.to_yaml()}
</code></pre>

<p>Once the basic setup is defined, running the minimization is done in just a few lines of code:</p>
<pre><code class="python">from elephas.hyperparam import HyperParamModel
from pyspark import SparkContext, SparkConf

# Create Spark context
conf = SparkConf().setAppName('Elephas_Hyperparameter_Optimization').setMaster('local[8]')
sc = SparkContext(conf=conf)

# Define hyper-parameter model and run optimization
hyperparam_model = HyperParamModel(sc)
hyperparam_model.minimize(model=model, data=data, max_evals=5)
</code></pre>

<h2 id="distributed-training-of-ensemble-models">Distributed training of ensemble models</h2>
<p>Building on the last section, it is possible to train ensemble models with elephas by means of running hyper-parameter 
optimization on large search spaces and defining a resulting voting classifier on the top-n performing models. 
With <code>data</code> and <code>model</code> defined as above, this is a simple as running</p>
<pre><code class="python">result = hyperparam_model.best_ensemble(nb_ensemble_models=10, model=model, data=data, max_evals=5)
</code></pre>

<p>In this example an ensemble of 10 models is built, based on optimization of at most 5 runs on each of the Spark workers.</p>
<h2 id="discussion">Discussion</h2>
<p>Premature parallelization may not be the root of all evil, but it may not always be the best idea to do so. Keep in 
mind that more workers mean less data per worker and parallelizing a model is not an excuse for actual learning. 
So, if you can perfectly well fit your data into memory <em>and</em> you're happy with training speed of the model consider 
just using keras.</p>
<p>One exception to this rule may be that you're already working within the Spark ecosystem and want to leverage what's 
there. The above SparkML example shows how to use evaluation modules from Spark and maybe you wish to further process 
the outcome of an elephas model down the road. In this case, we recommend to use elephas as a simple wrapper by setting 
num_workers=1.</p>
<p>Note that right now elephas restricts itself to data-parallel algorithms for two reasons. First, Spark simply makes it 
very easy to distribute data. Second, neither Spark nor Theano make it particularly easy to split up the actual model 
in parts, thus making model-parallelism practically impossible to realize.</p>
<p>Having said all that, we hope you learn to appreciate elephas as a pretty easy to setup and use playground for 
data-parallel deep-learning algorithms.</p>
<h2 id="literature">Literature</h2>
<p>[1] J. Dean, G.S. Corrado, R. Monga, K. Chen, M. Devin, QV. Le, MZ. Mao, M’A. Ranzato, A. Senior, P. Tucker, K. Yang, and AY. Ng. <a href="http://research.google.com/archive/large_deep_networks_nips2012.html">Large Scale Distributed Deep Networks</a>.</p>
<p>[2] F. Niu, B. Recht, C. Re, S.J. Wright <a href="http://arxiv.org/abs/1106.5730">HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a></p>
<p>[3] C. Noel, S. Osindero. <a href="http://stanford.edu/~rezab/nips2014workshop/submits/dogwild.pdf">Dogwild! — Distributed Hogwild for CPU &amp; GPU</a></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="why-use-elephas/" class="btn btn-neutral float-right" title="Why use Elephas">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="http://github.com/maxpumperla/elephas/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
      
        <span style="margin-left: 15px"><a href="why-use-elephas/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme.js" defer></script>
      <script src="search/main.js" defer></script>

</body>
</html>

<!--
MkDocs version : 1.0.1
Build Date UTC : 2018-08-21 15:09:49
-->
